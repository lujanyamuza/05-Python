{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se te deben: 415.0 €\n"
     ]
    }
   ],
   "source": [
    "qhours = input(\"¿Cuántas horas has trabajado?\")\n",
    "hour = float(qhours)   \n",
    "'''\n",
    "if hours == float():\n",
    "    continue\n",
    "else:\n",
    "    break\n",
    "'''\n",
    "\n",
    "qrate = input(\"¿A cuanto la hora?\")\n",
    "rate = float(qrate)\n",
    "\n",
    "\n",
    "\n",
    "if hour > 40:\n",
    "    result = (hour - 40) * rate * 1.5 + 40 * rate\n",
    "else:\n",
    "    result = hour * rate\n",
    "\n",
    "print(\"Se te deben:\", result, \"€\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#content\n",
      "#python-network\n",
      "/\n",
      "https://www.python.org/psf/\n",
      "https://docs.python.org\n",
      "https://pypi.org/\n",
      "/jobs/\n",
      "/community-landing/\n",
      "#top\n",
      "/\n",
      "https://psfmember.org/civicrm/contribute/transact?reset=1&id=2\n",
      "#site-map\n",
      "#\n",
      "javascript:;\n",
      "javascript:;\n",
      "javascript:;\n",
      "#\n",
      "https://www.facebook.com/pythonlang?fref=ts\n",
      "https://twitter.com/ThePSF\n",
      "/community/irc/\n",
      "/about/\n",
      "/about/apps/\n",
      "/about/quotes/\n",
      "/about/gettingstarted/\n",
      "/about/help/\n",
      "http://brochure.getpython.info/\n",
      "/downloads/\n",
      "/downloads/\n",
      "/downloads/source/\n",
      "/downloads/windows/\n",
      "/downloads/macos/\n",
      "/download/other/\n",
      "https://docs.python.org/3/license.html\n",
      "/download/alternatives\n",
      "/doc/\n",
      "/doc/\n",
      "/doc/av\n",
      "https://wiki.python.org/moin/BeginnersGuide\n",
      "https://devguide.python.org/\n",
      "https://docs.python.org/faq/\n",
      "http://wiki.python.org/moin/Languages\n",
      "http://python.org/dev/peps/\n",
      "https://wiki.python.org/moin/PythonBooks\n",
      "/doc/essays/\n",
      "/community/\n",
      "/community/diversity/\n",
      "/community/lists/\n",
      "/community/irc/\n",
      "/community/forums/\n",
      "/psf/annual-report/2021/\n",
      "/community/workshops/\n",
      "/community/sigs/\n",
      "/community/logos/\n",
      "https://wiki.python.org/moin/\n",
      "/psf/conduct/\n",
      "/community/awards\n",
      "/psf/get-involved/\n",
      "/psf/community-stories/\n",
      "/success-stories/\n",
      "/success-stories/category/arts/\n",
      "/success-stories/category/business/\n",
      "/success-stories/category/education/\n",
      "/success-stories/category/engineering/\n",
      "/success-stories/category/government/\n",
      "/success-stories/category/scientific/\n",
      "/success-stories/category/software-development/\n",
      "/blogs/\n",
      "/blogs/\n",
      "/psf/newsletter/\n",
      "http://pyfound.blogspot.com/\n",
      "http://pycon.blogspot.com/\n",
      "http://planetpython.org/\n",
      "/events/\n",
      "/events/python-events/\n",
      "/events/python-user-group/\n",
      "/events/python-events/past/\n",
      "/events/python-user-group/past/\n",
      "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
      "/shell/\n",
      "//docs.python.org/3/tutorial/controlflow.html#defining-functions\n",
      "//docs.python.org/3/tutorial/introduction.html#lists\n",
      "http://docs.python.org/3/tutorial/introduction.html#using-python-as-a-calculator\n",
      "//docs.python.org/3/tutorial/controlflow.html\n",
      "//docs.python.org/3/tutorial/\n",
      "/doc/\n",
      "/about/gettingstarted/\n",
      "/downloads/release/python-3113/\n",
      "https://docs.python.org\n",
      "//jobs.python.org\n",
      "https://blog.python.org\n",
      "https://pyfound.blogspot.com/2023/04/thank-you-for-many-years-of-service-van.html\n",
      "https://pyfound.blogspot.com/2023/04/the-eus-proposed-cra-law-may-have.html\n",
      "https://pythoninsider.blogspot.com/2023/04/its-time-for-another-set-of-python.html\n",
      "https://mailchi.mp/python/quick-pycon-us-update-its-in-april\n",
      "https://pyfound.blogspot.com/2023/03/protecting-python-trademarks.html\n",
      "/events/calendars/\n",
      "/events/python-user-group/1457/\n",
      "/events/python-user-group/1500/\n",
      "/events/python-events/1456/\n",
      "/events/python-events/1395/\n",
      "/events/python-events/1495/\n",
      "/success-stories/\n",
      "/success-stories/building-an-open-source-and-cross-platform-azure-cli-with-python/\n",
      "/success-stories/building-an-open-source-and-cross-platform-azure-cli-with-python/\n",
      "/about/apps\n",
      "http://www.djangoproject.com/\n",
      "http://www.pylonsproject.org/\n",
      "http://bottlepy.org\n",
      "http://tornadoweb.org\n",
      "http://flask.pocoo.org/\n",
      "http://www.web2py.com/\n",
      "http://wiki.python.org/moin/TkInter\n",
      "https://wiki.gnome.org/Projects/PyGObject\n",
      "http://www.riverbankcomputing.co.uk/software/pyqt/intro\n",
      "https://wiki.qt.io/PySide\n",
      "https://kivy.org/\n",
      "http://www.wxpython.org/\n",
      "http://www.scipy.org\n",
      "http://pandas.pydata.org/\n",
      "http://ipython.org\n",
      "http://buildbot.net/\n",
      "http://trac.edgewall.org/\n",
      "http://roundup.sourceforge.net/\n",
      "http://www.ansible.com\n",
      "https://saltproject.io\n",
      "https://www.openstack.org\n",
      "https://xon.sh\n",
      "/dev/peps/\n",
      "/dev/peps/peps.rss\n",
      "/psf/\n",
      "/psf/\n",
      "/users/membership/\n",
      "/psf/donations/\n",
      "#python-network\n",
      "/about/\n",
      "/about/apps/\n",
      "/about/quotes/\n",
      "/about/gettingstarted/\n",
      "/about/help/\n",
      "http://brochure.getpython.info/\n",
      "/downloads/\n",
      "/downloads/\n",
      "/downloads/source/\n",
      "/downloads/windows/\n",
      "/downloads/macos/\n",
      "/download/other/\n",
      "https://docs.python.org/3/license.html\n",
      "/download/alternatives\n",
      "/doc/\n",
      "/doc/\n",
      "/doc/av\n",
      "https://wiki.python.org/moin/BeginnersGuide\n",
      "https://devguide.python.org/\n",
      "https://docs.python.org/faq/\n",
      "http://wiki.python.org/moin/Languages\n",
      "http://python.org/dev/peps/\n",
      "https://wiki.python.org/moin/PythonBooks\n",
      "/doc/essays/\n",
      "/community/\n",
      "/community/diversity/\n",
      "/community/lists/\n",
      "/community/irc/\n",
      "/community/forums/\n",
      "/psf/annual-report/2021/\n",
      "/community/workshops/\n",
      "/community/sigs/\n",
      "/community/logos/\n",
      "https://wiki.python.org/moin/\n",
      "/psf/conduct/\n",
      "/community/awards\n",
      "/psf/get-involved/\n",
      "/psf/community-stories/\n",
      "/success-stories/\n",
      "/success-stories/category/arts/\n",
      "/success-stories/category/business/\n",
      "/success-stories/category/education/\n",
      "/success-stories/category/engineering/\n",
      "/success-stories/category/government/\n",
      "/success-stories/category/scientific/\n",
      "/success-stories/category/software-development/\n",
      "/blogs/\n",
      "/blogs/\n",
      "/psf/newsletter/\n",
      "http://pyfound.blogspot.com/\n",
      "http://pycon.blogspot.com/\n",
      "http://planetpython.org/\n",
      "/events/\n",
      "/events/python-events/\n",
      "/events/python-user-group/\n",
      "/events/python-events/past/\n",
      "/events/python-user-group/past/\n",
      "https://wiki.python.org/moin/PythonEventsCalendar#Submitting_an_Event\n",
      "/dev/\n",
      "https://devguide.python.org/\n",
      "https://bugs.python.org/\n",
      "https://mail.python.org/mailman/listinfo/python-dev\n",
      "/dev/core-mentorship/\n",
      "/dev/security/\n",
      "#python-network\n",
      "/about/help/\n",
      "/community/diversity/\n",
      "https://github.com/python/pythondotorg/issues\n",
      "https://status.python.org/\n",
      "/psf-landing/\n",
      "/about/legal/\n",
      "/privacy/\n",
      "/psf/sponsorship/sponsors/#heroku\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = input(\"Inserte url: \")\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tags = soup('a')\n",
    "print(tags)\n",
    "for tag in tags:\n",
    "    print(tag.get('href'))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. HTTP\n",
    "Write a program that asks the user for an http/s address, and later, extracts all existing http addresses from that website and saves them in a file called urls.txt (one line for each address)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x000001B1ECD31630>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error #abrir y leer webs, analizar urls, manejar errores\n",
    "import re #trabajar con regular expressions\n",
    "#import pathlib \n",
    "\n",
    "#path = str(pathlib.Path(__file__).parent.absolute()) \n",
    "#obtener la ruta absoluta del archivo en el que se encuentra este código (variable path)\n",
    "\n",
    "web = input('Introduce una web: ')\n",
    "\n",
    "url_pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(web) as response: #abrir la url y almacenarla en la variable response\n",
    "        charset = response.info().get_content_charset() \n",
    "        html = response.read().decode(charset)\n",
    "\n",
    "        urls = re.findall(url_pattern, html) #buscar en la variable html con las caracteristicas del url_pattern\n",
    "        with open('urls.txt', 'w') as fsave:\n",
    "            for url in urls:\n",
    "                fsave.write(url)\n",
    "                fsave.write('\\n')\n",
    "except ValueError:\n",
    "    print('La dirección de correo no es correcta')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. HREF\n",
    " Write a program that prompts the user for an http/s address, and then extracts all existing http addresses in links on that website and stores them in a file called href.txt (one line for each address)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m urls \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m     31\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mhrefs.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fsave:\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tags:\n\u001b[0;32m     33\u001b[0m         fsave\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(url))\n\u001b[0;32m     34\u001b[0m         fsave\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tags' is not defined"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "#import pathlib\n",
    "import re\n",
    "\n",
    "MAX_DEPTH = 1\n",
    "\n",
    "url_pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "def ExtractUrl(url, urls, depth):\n",
    "    html = urllib.request.urlopen(web).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    tags = soup('a')\n",
    "    for tag in tags:\n",
    "        link = tag.get('href', None)\n",
    "        if link is None:\n",
    "            continue\n",
    "        if re.search(url_pattern, link):\n",
    "            urls[link] = urls.get(link, 0) + 1\n",
    "            if depth < MAX_DEPTH:\n",
    "                ExtractUrl(link, urls, depth + 1)\n",
    "\n",
    "#path = str(pathlib.Path(__file__).parent.absolute())\n",
    "\n",
    "\n",
    "web = input('Entrer a web: ')\n",
    "\n",
    "try:\n",
    "    urls = dict()\n",
    "    with open('hrefs.txt', 'w') as fsave:\n",
    "        for tag in tags:\n",
    "            fsave.write('{} - {}'.format(url))\n",
    "            fsave.write('\\n')\n",
    "except ValueError:\n",
    "    print('The web address entered is not correct')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "\n",
      "It is the east and Juliet is the sun\n",
      "\n",
      "Arise fair sun and kill the envious moon\n",
      "\n",
      "Who is already sick and pale with grief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n",
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts) #para qué querría hacer esto?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User count: 2\n",
      "Name Chuck\n",
      "Id 001\n",
      "Attribute 2\n",
      "Name Chuck\n",
      "Id 009\n",
      "Attribute 7\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "input = '''[\n",
    "    { \"id\" : \"001\",\n",
    "    \"x\" : \"2\",\n",
    "    \"name\" : \"Chuck\"\n",
    "    } ,\n",
    "    { \"id\" : \"009\",\n",
    "    \"x\" : \"7\",\n",
    "    \"name\" : \"Chuck\"\n",
    "    }\n",
    "    ]'''\n",
    "info = json.loads(input)\n",
    "print('User count:', len(info))\n",
    "for item in info:\n",
    "    print('Name', item['name'])\n",
    "    print('Id', item['id'])\n",
    "    print('Attribute', item['x'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sally constructed\n",
      "Jim constructed\n",
      "Sally party count 1\n",
      "Jim party count 1\n",
      "Sally party count 2\n",
      "Sally party count 3\n"
     ]
    }
   ],
   "source": [
    "class PartyAnimal:\n",
    "    x = 0\n",
    "    name = \"\"\n",
    "    def __init__(self, z):\n",
    "        self.name = z\n",
    "        print(self.name,\"constructed\")\n",
    "    def party(self) :\n",
    "        self.x = self.x + 1\n",
    "        print(self.name,\"party count\",self.x)\n",
    "s = PartyAnimal(\"Sally\")\n",
    "j = PartyAnimal(\"Jim\")\n",
    "s.party()\n",
    "j.party()\n",
    "s.party()\n",
    "s.party()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
